% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This TeX file is part of the course
%%%% Introduction to Scientific Programming in C++/Fortran2003
%%%% copyright 2017/8 Victor Eijkhout eijkhout@tacc.utexas.edu
%%%%
%%%% google.tex : exercises for pagerank
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Level 0 {Basic ideas}

We are going to simulate the Internet. In particular, we are going to
simulate the \indexterm{Pagerank} algorithm by which
\indexterm{Google} determines the importance of web pages.

Let's start with some basic classes: 
\begin{itemize}
\item A \n{Page} contains some information such as its title and a
  global numbering in Google's datacenter. It also contains a
  collection of links.
\item A \n{Link} is a pointer to a \n{Page}. It can contain further
  information such as probability of being clicked, or number of times
  clicked.
\item Ultimately we want to have a class \n{Web} which contains a
  number of pages and their links. The web object will ultimately also
  contain information such as relative importance of the pages.
\end{itemize}

This application is a natural one for using pointers. When you click
on a link on a web page you go from looking at one page in your
browser to looking at another. You could implement this by having a
pointer to a page, and clicking updates the value of this pointer.

\begin{exercise}
  Make a class \n{Page} which initially just contains the name of the
  page. Write a method to display the page. Since we will be using
  pointers quite a bit, let this be the intended code for testing:
  %
  \verbatimsnippet{homepage}

  Next, make a class \n{Link}. A~link is metaphorically a pointer to
  another page, so let the main member of the \n{Link} class be a
  \n{shared_ptr<Page>}. Write two methods; one to display the link,
  and one \n{click} that follows the link. Intended code:
  %
  \verbatimsnippet{utlink}
\end{exercise}

\begin{exercise}
  Add some more links to your homepage. Write a method
  \n{random_click} for the \n{Page} class. Intended code:
  %
  \verbatimsnippet{randomclick}
  %
  How do you handle the case of a page without links?
\end{exercise}

\Level 0 {Clicking around}

\begin{exercise}
  Now make a class \n{Web} which foremost contains a bunch
  (technically: a~\n{vector}) of pages. Or rather: of pointers to
  pages.
  Since we don't want to build a whole internet by hand, let's have a
  method \n{create_random_links} which makes a random number of links
  to random pages.
  Intended code:
  %
  \verbatimsnippet{makeweb}

  Now we can start our simulation. Write a method \n{Web::random_walk}
  that takes a page, and the length of the walk, and simulates the
  result of randomly clicking that many times on the current
  page. (Current page. Not the starting page.)
\end{exercise}

Let's start working towards PageRank. First we see if there are pages
that are more popular than others. You can do that by starting a
random walk once on each page. Or maybe a couple of times.

\begin{exercise}
  Apart from the size of, what other design parameters are there for
  your tests? Can you give a back-of-the-envelope estimation of their effect?
\end{exercise}

\begin{exercise}
  Your first simulation is to start on each page a number of times,
  and counts where that lands you.
  Intended code:
  %
  \verbatimsnippet{walkrandomly}

  Display the results and analyze. You may find that you finish on
  certain pages too many times. What's happening?
\end{exercise}

\Level 0 {Graph algorithms}

There are many algorithms that rely on gradually traversing the
web. For instance, any graph can be
\emph{connected}\index{graph!connected}. You test that by
\begin{itemize}
\item Take an arbitrary vertex~$v$. Make a `reachable set'
  $R\leftarrow\{v\}$.
\item Now see where you can get from your reachable set:
  \[ \forall_{v\in V}\forall_{\hbox{$w$ neighbour of $v$}}\colon
  R\leftarrow R\cup \{w\}
  \]
\item Repeat the previous step until $R$ does not change anymore. 
\end{itemize}
After this algorithm concludes, is $R$ equal to your set of vertices?
If so, your graph is called (fully) connected. If not, your graph has
multiple
%
\emph{connected components}\index{connected components|see{graph, connected}}.

\begin{exercise}
  \label{ex:SSSD}
  Code the above algorithm, keeping track of how many steps it takes
  to reach each vertex~$w$. This is the \indexterm{Single Source
    Shortest Path} algorithm (for unweighted graphs).

  The \emph{diameter}\index{graph!diameter} is defined as the maximal
  shortest path. Code this.
\end{exercise}

\Level 0 {Page ranking}

The Pagerank algorithm now asks, if you keep clicking randomly, what
is the distribution of how likely you are to wind up on a certain
page. The way we calculate that is with a probability distribution: we
assign a probability to each page so that the sum of all probabilities
is~one. We start with a random distribution:
%
\snippetwithoutput{pdfsetup}{google}{pdfsetup}

\endinput

Assuming you
have learned about arrays~\ref{ch:array}, in particular the use of
\n{std::vector}.

The web can be represented as a matrix~$W$ of size~$N$, the number of web
pages, where $w_{ij}=1$ if page~$i$ has a link to page~$j$ and zero
otherwise. However, this representation is only conceptual; if you
actually stored this matrix it would be gigantic and largely full of
zeros. Therefore we use a \indextermsub{sparse}{matrix}: we store only
the pairs $(i,j)$ for which $w_{ij}\not=0$. (In this case we can get
away with storing only the indices; in a general sparse matrix you
also need to store the actual~$w_{ij}$ value.)

\begin{exercise}
  Store the sparse matrix representing the web as a
\begin{verbatim}
vector< vector<bool> > web;
\end{verbatim}
  structure.
  \begin{enumerate}
  \item At first, assume that the number of web pages is given and reserve the outer
    vector. Read in values for nonzero indices and add those to the
    matrix structure.
  \item Then, assume that the number of pages is not pre-determined. Read in
    indices; now you need to create rows as they are needed. Suppose
    the requested indices are
\begin{verbatim}
5,1
3,5
1,3
\end{verbatim}
    Since your structure has only three rows, you also need to remeber
    their row numbers.
  \end{enumerate}
\end{exercise}

Now we want to model the behaviour of a person clicking on links.

\begin{exercise}
  Track the probability that a user is on a certain page with a
  \indextermsub{probability}{vector}:
\begin{verbatim}
vector<float> state;
\end{verbatim}
  The sum of the entries needs to be~$1$. While the algorithms will
  mathematically guarantee this, it may be a good idea to test for it
  every once in a while.

  Now model the user clicking on a link by computing a new probability
  vector:
  \begin{itemize}
  \item if for some page~$p$ \n{state[p]} is positive,
  \item then for all links~$q$, where \n{web[p][q]} is true,
  \item the new state gets a contribution of \n{state[p]} divided by
    the number of $q$-links.
  \end{itemize}
  Do you recognize a linear algebra algorithm?
\end{exercise}

Together this gives an approximation of Google's \indexterm{PageRank}
algorithm.
